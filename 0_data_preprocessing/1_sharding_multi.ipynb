{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c15fb0b3-888c-4713-b358-2c8961b177b1",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 alxyok\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40589b09-ef34-4bd9-8540-1beadc29aa6d",
   "metadata": {},
   "source": [
    "****************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e7e12-dac9-47c4-8d67-a210ff80daea",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288f6e76-7246-4409-b7ea-2ce46e32d64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c8819-af9e-40de-84c1-12d2361ce88a",
   "metadata": {},
   "source": [
    "### Quick-note on project directory\n",
    "\n",
    "The main root dir `~/3dcorrection` is structured as follow:\n",
    "* `data/` contains raw and preprocessed data. \n",
    "    * `raw/` is actually a symbolic link to the same repo for all candidates, DO NOT TOUCH IT!\n",
    "    * `processed/` will be created when data is preprocessed and will contain all transformed data\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1bf27e-f883-4624-a3ff-d7de8bfb7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_path = os.path.join('/', 'home', 'jupyter', 'bootcamps')\n",
    "\n",
    "data_path = os.path.join(root_path, 'data')\n",
    "cache_path = os.path.join(data_path, 'cache')\n",
    "raw_data_path = os.path.join(data_path, 'raw')\n",
    "processed_data_path = os.path.join(data_path, 'processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c9021-6097-4edc-b596-ab9758bc32cb",
   "metadata": {},
   "source": [
    "### The 3D Correction Use-Case\n",
    "\n",
    "The European Centre for Medium-range Weather Forecasts (ECMWF) has developed a series of model giving the current best accurate parametrization scheme available—among those, SPARTACUS delivers **radiation** prediction over the globe. Because it is demanding in computations, a simpler, degraded model called TRIPLECLOUD is developed to satisfy the production environment constraints. \n",
    "\n",
    "Like most climate models, to leverage hardware acceleration, the choice is made to split the globe in blocks—this has the immediate consequence of losing the spatial correlation for a gain in parallelization. \n",
    "\n",
    "The unit block is a column that express values throughout the vertical dimension over a set of levels. Each level is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8e048-4c2e-42a6-bab2-35060ca35353",
   "metadata": {},
   "source": [
    "Now let's load the raw data we'll be using throughout this hands-on. Take a look at the [source notebook](https://git.ecmwf.int/projects/MLFET/repos/maelstrom-radiation/browse/climetlab_maelstrom_radiation/radiation.py) for a more info on the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a82a516-48d1-471b-9b08-758be80e258f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climetlab as cml\n",
    "import dask\n",
    "import dask.array as da\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import xarray as xr\n",
    "\n",
    "import config\n",
    "import shard_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33011fa5-a07e-4a00-abb9-1f857aa61db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# MIT License\n",
      "#\n",
      "# Copyright (c) 2022 alxyok\n",
      "#\n",
      "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "# of this software and associated documentation files (the \"Software\"), to deal\n",
      "# in the Software without restriction, including without limitation the rights\n",
      "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "# copies of the Software, and to permit persons to whom the Software is\n",
      "# furnished to do so, subject to the following conditions:\n",
      "#\n",
      "# The above copyright notice and this permission notice shall be included in all\n",
      "# copies or substantial portions of the Software.\n",
      "#\n",
      "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "# SOFTWARE.\n",
      "\n",
      "import h5py\n",
      "from mpi4py import MPI\n",
      "import numpy as np\n",
      "import os.path as osp\n",
      "\n",
      "import config\n",
      "\n",
      "\n",
      "def main():\n",
      "    \n",
      "    step = 250\n",
      "    h5_path = osp.join(config.processed_data_path, f'feats-{step}.h5')\n",
      "\n",
      "    rank = MPI.COMM_WORLD.rank\n",
      "\n",
      "    for subidx in np.arange(53):\n",
      "\n",
      "        start = rank * 53 * 2 ** 4 + subidx * 4800\n",
      "        end = start + 4800\n",
      "\n",
      "        # with h5py.File(h5_path, 'r', driver='mpio', comm=MPI.COMM_WORLD) as feats:\n",
      "        with h5py.File(h5_path, 'r') as feats:\n",
      "\n",
      "            sharded_path = osp.join(config.processed_data_path, f'feats-{step}.{rank}.{subidx}.h5')\n",
      "            # with h5py.File(sharded_path, 'w', driver='mpio', comm=MPI.COMM_WORLD) as sharded:\n",
      "            with h5py.File(sharded_path, 'w') as sharded:\n",
      "\n",
      "                sharded.create_dataset(\"/x\", data=feats['/x'][start:end])\n",
      "                sharded.create_dataset(\"/y\", data=feats['/y'][start:end])\n",
      "                sharded.create_dataset(\"/edge\", data=feats['/edge'][start:end])\n",
      "                \n",
      "                \n",
      "if __name__ == \"__main__\":\n",
      "    \n",
      "    main()"
     ]
    }
   ],
   "source": [
    "!cat shard_parallel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de9c5b-eb98-4136-9f7a-c1525b39eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 16 python shard_parallel.py"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
