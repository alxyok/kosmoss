{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c15fb0b3-888c-4713-b358-2c8961b177b1",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 alxyok\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40589b09-ef34-4bd9-8540-1beadc29aa6d",
   "metadata": {},
   "source": [
    "****************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4777da-a65f-45d2-bddb-d0b4c85db802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the root of this bootcamp\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "sys.path.append(osp.abspath('..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e7e12-dac9-47c4-8d67-a210ff80daea",
   "metadata": {},
   "source": [
    "# Computing basic Stats with the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0db00-d0b0-4b51-a603-ced9f855d47d",
   "metadata": {},
   "source": [
    "There are many framework in the tech stack to push for gpu-based processing including the *Rapids.ai* collection of tools developed partly by **Nvidia** and an Open Source project, but until the hardware converges to the unified memory, this initiative has very limited use-cases in the overall scientific ML algorithmic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d4852-2a58-4df9-a537-daca1521fb69",
   "metadata": {},
   "source": [
    "We'll explore those limits in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330287a5-cda4-4368-b64b-00288ba71d3a",
   "metadata": {},
   "source": [
    "Let's first load the data from NumPy files using Dask lazy loading. For the sake of the demonstration, let's load only `x` for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82a516-48d1-471b-9b08-758be80e258f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "\n",
    "import config\n",
    "import utils \n",
    "\n",
    "step = config.config['timestep']\n",
    "num_workers = config.config['num_workers']\n",
    "\n",
    "feats_path = osp.join(config.processed_data_path, f'features-{step}')\n",
    "\n",
    "x = da.from_npy_stack(osp.join(feats_path, 'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20dbbb3-a7c1-489a-a8f5-656f58ce3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.timing\n",
    "def load_and_push_gpu(x: da.Array) -> None:\n",
    "    \n",
    "    with cp.cuda.Device(0):\n",
    "        \n",
    "        # Loading the data into CPU memory\n",
    "        x_ = cp.array(x.compute(num_workers=num_workers))\n",
    "        \n",
    "        # Pushing the data into GPU memory\n",
    "        x_mean_gpu = cp.mean(x_, axis=0)\n",
    "        \n",
    "        # Retrieving the data from GPU to CPU\n",
    "        x_mean_cpu_back = cp.asnumpy(x_mean_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ec4cd8-de09-4527-99dd-1deb36e7df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97405.09 ms\n"
     ]
    }
   ],
   "source": [
    "load_and_push_gpu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b61a1222-78e5-4ee6-ab87-dd2e25c51801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496af216-7f3a-4dd9-8b12-38f92e9c8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.timing\n",
    "def multi_cpu_stats_compute_reminder(x: da.Array) -> None:\n",
    "    x_mean_multi_cpu = da.mean(x, axis=0).compute(num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352998b5-2ce3-4625-bada-ee6b7ba15def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946.51 ms\n"
     ]
    }
   ],
   "source": [
    "multi_cpu_stats_compute_reminder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4687c1-0229-46f2-a9b7-7ca8a40e8d02",
   "metadata": {},
   "source": [
    "No Comment.\n",
    "\n",
    "Actually yes. Three. \n",
    "\n",
    "* It starts to become interesting when the original dataset size grows. But since the GPU is really memory bound, it rapidly becomes a bottleneck. Waiting for a definitive unified memory architecture.\n",
    "* If you want to overcome the memory bottleneck, you have to take of all the boiler plate, which is why you turn to framework in the first place is to avoid this.\n",
    "* Using GPUDirect could improve overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5da651-faf2-41a1-896b-e62f4f99cd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
