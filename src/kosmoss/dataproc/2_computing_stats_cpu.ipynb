{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523e7e12-dac9-47c4-8d67-a210ff80daea",
   "metadata": {},
   "source": [
    "# Computing basic Stats with the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44579b2c-994b-484e-990e-2400c057e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kosmoss import CONFIG, DATA_PATH, PROCESSED_DATA_PATH\n",
    "from kosmoss.utils import timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a82a516-48d1-471b-9b08-758be80e258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import torch\n",
    "from typing import Dict, List, Text\n",
    "\n",
    "step = CONFIG['timestep']\n",
    "num_workers = CONFIG['num_workers']\n",
    "\n",
    "features_path = osp.join(PROCESSED_DATA_PATH, f'features-{step}')\n",
    "\n",
    "x = da.from_npy_stack(osp.join(features_path, 'x'))\n",
    "y = da.from_npy_stack(osp.join(features_path, 'y'))\n",
    "edge = da.from_npy_stack(osp.join(features_path, 'edge'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7dbd6d1-d425-4120-a9b6-467f1781540e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 11.16 GiB </td>\n",
       "                        <td> 13.48 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1085440, 138, 20) </td>\n",
       "                        <td> (1280, 138, 20) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 848 Tasks </td>\n",
       "                        <td> 848 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"29\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"36\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"51\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"55\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"58\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"62\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"50\" y2=\"66\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"73\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"77\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"81\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"69\" y2=\"84\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"73\" y2=\"88\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"92\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"39\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"46\" y2=\"11\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"53\" y2=\"18\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"61\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"65\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"68\" y2=\"33\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"72\" y2=\"37\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"76\" y2=\"40\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"83\" y2=\"48\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"87\" y2=\"51\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"91\" y2=\"55\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"94\" y2=\"59\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"98\" y2=\"63\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"102\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >20</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,126.000852,83.294544)\">138</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">1085440</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-npy-stack-/home/jupyter/.kosmoss/data/processed/features, shape=(1085440, 138, 20), dtype=float32, chunksize=(1280, 138, 20), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685ad64-f2df-41e3-8861-8399805b137f",
   "metadata": {},
   "source": [
    "## Loading in a single thread with pure NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61716425-07b2-4904-9b58-7e319b99ad98",
   "metadata": {},
   "source": [
    "Several cons to using this method:\n",
    "\n",
    "* Slow, monothreaded data loading\n",
    "* Requires to load the entire file content at once into memory\n",
    "* Can be limited depending on the amount of available RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf7401a-688f-4e2d-a999-233da03ed6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def compute_stats_mono(arrays: List[da.Array]) -> Dict[Text, np.ndarray]:\n",
    "    \n",
    "    # Simulate pure NumPy\n",
    "    num_workers = 1\n",
    "    \n",
    "    stats = {}\n",
    "    for a in arrays:\n",
    "        \n",
    "        # Load data into memory\n",
    "        a_ = a.compute(num_workers=num_workers)\n",
    "        \n",
    "        # Compute mean and standard-deviation for array\n",
    "        a_mean = np.mean(a_, axis=0)\n",
    "        a_std = np.std(a_, axis=0)\n",
    "        \n",
    "        name = a.name.split(\"/\")[-1]\n",
    "        stats.update({\n",
    "            f'{name}_mean': torch.tensor(a_mean),\n",
    "            f'{name}_std': torch.tensor(a_std)\n",
    "        })\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c48baa-63d0-4994-8a79-472b4791fc06",
   "metadata": {},
   "source": [
    "Open an `htop` in a side terminal, and watch the memory grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d56934-8962-4b4a-a07a-31a5a3619519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280975.03 ms\n"
     ]
    }
   ],
   "source": [
    "stats = compute_stats_mono([x, y, edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bcfaa3-167d-48ba-9ef6-18ead9b84e3f",
   "metadata": {},
   "source": [
    "## Multithreaded loading with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f405df6-2e92-4fdc-ad5f-89d0161ea046",
   "metadata": {},
   "source": [
    "Again, most of the process in *Dask* is handled in lazy evaluation mode. Dask builds a computational graph called a *Directed Acyclic Graph* (DAG) and executes the command only if needed, proceeding with optimizations along the way, if any.\n",
    "\n",
    "Moreover, the `compute()` method executes the DAG on each data chunk by using Math formula to distribute computations when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd5298b-24ea-45e1-8bd6-87dcb5ab6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def compute_stats_multi(arrays: List[da.Array]) -> Dict[Text, np.ndarray]:\n",
    "    \n",
    "    # Scaling computation by increasing default number of workers\n",
    "    num_workers = 16\n",
    "    \n",
    "    stats = {}\n",
    "    for a in arrays:\n",
    "        \n",
    "        # Lazy evaluation\n",
    "        a_mean = da.mean(a, axis=0)\n",
    "        a_std = da.std(a, axis=0)\n",
    "        \n",
    "        # Compute mean and standard-deviation for current array\n",
    "        m = a_mean.compute(num_workers=num_workers)\n",
    "        s = a_std.compute(num_workers=num_workers)\n",
    "        \n",
    "        name = a.name.split(\"/\")[-1]\n",
    "        stats.update({\n",
    "            f'{name}_mean': torch.tensor(m),\n",
    "            f'{name}_std': torch.tensor(s)\n",
    "        })\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2fc5c5-fdca-4170-a024-a86c313f876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18083.31 ms\n"
     ]
    }
   ],
   "source": [
    "stats = compute_stats_multi([x, y, edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96ef7b-2a3d-4964-87e4-44bf5662687e",
   "metadata": {},
   "source": [
    "You should observe a substantial gain in computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ce3d7-8302-41d7-ac27-fef086fa8cd9",
   "metadata": {},
   "source": [
    "## Saving the Stats for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de63c9-fd28-45b3-ad12-2858a1aeb61b",
   "metadata": {},
   "source": [
    "We will use this data to perform on-the-fly input normalization within the model itself with a Normalization layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d4a6b-c3ef-497e-a2bd-cf5193c401a4",
   "metadata": {},
   "source": [
    "`torch.save` uses the Python Pickle format to save data. You can save anything pickable, which is not exactly a limitation since many pure Python code is pickle-serializable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97481da6-fbca-4947-aca2-9c1e8c83d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_path = osp.join(DATA_PATH, f\"stats-features-{step}.pt\")\n",
    "torch.save(stats, stats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168dadfb-ce23-4623-8634-ee05bc2ae5b7",
   "metadata": {},
   "source": [
    "# Same for the Flattened dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419bde07-d988-4ec8-84cd-94c01dd9299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49732.58 ms\n"
     ]
    }
   ],
   "source": [
    "flattened_path = osp.join(PROCESSED_DATA_PATH, f'flattened-{step}')\n",
    "\n",
    "x = da.from_npy_stack(osp.join(flattened_path, 'x'))\n",
    "y = da.from_npy_stack(osp.join(flattened_path, 'y'))\n",
    "\n",
    "stats = compute_stats_multi([x, y])\n",
    "\n",
    "stats_path = osp.join(DATA_PATH, f\"stats-flattened-{step}.pt\")\n",
    "torch.save(stats, stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d16c2-250d-450f-aa35-318c20f5ca3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
