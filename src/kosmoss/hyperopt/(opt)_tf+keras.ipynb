{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a4e962-6f93-4be6-b3f4-442328c1156c",
   "metadata": {},
   "source": [
    "# HPO w/ TensorFlow + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b37caf-4bb4-462b-80bd-f7543528c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climetlab\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import randomname\n",
    "\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hebo import HEBOSearch\n",
    "from ray.tune.integration.keras import TuneReportCallback\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class HRLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, name=None, **kwargs):\n",
    "        super(HRLayer, self).__init__(name=name, **kwargs)\n",
    "        self.g_cp = tf.constant(9.80665 / 1004 * 24 * 3600)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        hlpress = inputs[1] \n",
    "        netflux = inputs[0]\n",
    "        \n",
    "        flux_diff = netflux[..., 1:] - netflux[..., :-1]\n",
    "        net_press = hlpress[..., 1:, 0] - hlpress[..., :-1, 0]\n",
    "        \n",
    "        return -self.g_cp * tf.math.divide(flux_diff, net_press)\n",
    "\n",
    "    \n",
    "    \n",
    "def create_datasets(config):\n",
    "\n",
    "    def parse_fn(X):\n",
    "        \n",
    "        x, y = X\n",
    "        \n",
    "        new_x = {}\n",
    "        new_y = {}\n",
    "        \n",
    "        for key in x.keys():\n",
    "            \n",
    "            if key == 'col_inputs':\n",
    "                indices = [10, 23, 24, 25, 26]\n",
    "                new_x[key] = tf.gather(x['col_inputs'], indices, axis=2)\n",
    "                \n",
    "            elif key == 'sca_inputs':\n",
    "                indices = list(range(14)) + [16]\n",
    "                new_x[key] = tf.gather(x['sca_inputs'], indices, axis=1)\n",
    "                \n",
    "            else:\n",
    "                new_x[key] = x[key]\n",
    "                \n",
    "        for key in y.keys():\n",
    "            if \"sw\" in key:\n",
    "                new_y[key] = y[key]\n",
    "\n",
    "        new_y[\"sw_diff\"] = new_y[\"sw\"][..., 0] - new_y[\"sw\"][..., 1]\n",
    "        new_y[\"sw_add\"] = new_y[\"sw\"][..., 0] + new_y[\"sw\"][..., 1]\n",
    "        new_y.pop(\"sw\")\n",
    "\n",
    "        return new_x, new_y\n",
    "    \n",
    "\n",
    "    cml.settings.set(\"cache-directory\", CACHE_DATA_PATH)\n",
    "    ds = cml.load_dataset('maelstrom-radiation-tf',\n",
    "                          dataset = '3dcorrection',\n",
    "                          timestep = list(range(0, 3501, 1000)), \n",
    "                          filenum = list(range(5)),\n",
    "                          norm=True,\n",
    "                          hr_units=\"K d-1\",)\n",
    "    \n",
    "    tfds = ds.to_tfdataset(batch_size=config[\"batch_size\"], repeat=False)\n",
    "    tfds = tfds.map(parse_fn)\n",
    "    tfds = tfds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    valsize = 271360 // int(config[\"batch_size\"])\n",
    "    valds = tfds.take(valsize)\n",
    "    trainds = tfds.skip(valsize)\n",
    "    \n",
    "    return trainds, valds\n",
    "\n",
    "def create_model(config):\n",
    "\n",
    "    def build_model():\n",
    "\n",
    "        # Assuming inputs have the order: scalar, column, hl, inter, pressure_hl\n",
    "        all_inp = [tf.keras.Input(\n",
    "            inp_spec[k].shape[1:], \n",
    "            name=k) for k in config[\"input_spec\"].key()\n",
    "        ]\n",
    "\n",
    "        col_inp = tf.keras.layers.Flatten()(all_inp[1])\n",
    "        hl_inp = tf.keras.layers.Flatten()(all_inp[2])\n",
    "        inter_inp = tf.keras.layers.Flatten()(all_inp[3])\n",
    "        dense = tf.keras.layers.Concatenate(axis=-1)([all_inp[0], hl_inp, col_inp, inter_inp])\n",
    "\n",
    "        for _ in range(config[\"depth\"]):\n",
    "\n",
    "            dense = tf.keras.layers.Dense(\n",
    "                config[\"width\"],\n",
    "                activation=config[\"activation\"],\n",
    "                kernel_initializer='he_uniform',\n",
    "                kernel_regularizer=tf.keras.regularizers.l1_l2(l1=config[\"l1\"], l2=config[\"l2\"]),\n",
    "            )(dense)\n",
    "\n",
    "            if config[\"dropout\"]:\n",
    "                dense = tf.keras.layers.Dropout(0.5)(dense)\n",
    "\n",
    "        sw_diff = tf.keras.layers.Dense(138, activation='linear', name=\"sw_diff\")(dense)\n",
    "        sw_add = tf.keras.layers.Dense(138, activation=\"linear\", name=\"sw_add\")(dense)\n",
    "\n",
    "        hr_sw = HRLayer(name=\"hr_sw\")([sw_diff, all_inp[-1]])\n",
    "\n",
    "        return {\n",
    "            \"inputs\": all_inp, \n",
    "            \"outputs\": (sw_diff, sw_add, hr_sw)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # inputs, outputs = build_model()\n",
    "\n",
    "    o = ['hr_sw', 'sw_diff', 'sw_add']\n",
    "    losses = {k: 'mse' for k in o}\n",
    "    loss_weights = {K: 1 for k in o}\n",
    "    model = tf.keras.Model(**build_model())\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae')]\n",
    "\n",
    "    model.compile(loss=losses, \n",
    "                  optimizer=optimizer, \n",
    "                  loss_weights=loss_weights, \n",
    "                  metrics=metrics)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_mlp(config, data=None, num_epochs=50):\n",
    "    \n",
    "    trainds, valds = create_datasets()\n",
    "    config[\"input_spec\"] = trainds.element_spec[0]\n",
    "    \n",
    "    model = create_model(config)\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=num_epochs,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            TuneReportCallback({\n",
    "                \"loss\" : \"val_loss\",\n",
    "                \"hr_mae\" : \"val_hr_sw_mae\",\n",
    "            })\n",
    "        ])\n",
    "\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    config = {\n",
    "        \"num_epochs\": 50,\n",
    "        \"batch_size\" : int(tune.choice([64, 128, 256]).sample()),\n",
    "        \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n",
    "        \"width\": tune.choice([128, 256, 512]),\n",
    "        \"depth\": tune.randint(1, 10),\n",
    "        \"l1\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"l2\": tune.loguniform(1e-5, 1e-2),\n",
    "        \"dropout\": tune.choice([True, False]),\n",
    "        \"activation\": \"swish\"\n",
    "    }\n",
    "    \n",
    "    train_mlp_param = tune.with_parameters(train_mlp, \n",
    "                                           num_epochs=config[\"num_epochs\"])\n",
    "    \n",
    "    analysis = tune.run(\n",
    "        train_mlp_param,\n",
    "        name=xp_name,\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        scheduler=AsyncHyperBandScheduler(\n",
    "            max_t=num_epochs,\n",
    "            grace_period=10,\n",
    "            reduction_factor=4\n",
    "        ),\n",
    "        search_alg=HEBOSearch(),\n",
    "        num_samples=10,\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 2, \n",
    "            \"gpu\": 1\n",
    "        },\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
