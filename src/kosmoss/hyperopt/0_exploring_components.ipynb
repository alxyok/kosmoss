{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523e7e12-dac9-47c4-8d67-a210ff80daea",
   "metadata": {},
   "source": [
    "# Ray.io optimization framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6b04cb-6c23-4f60-b830-d1f23184290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray.tune as tune\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a16b2-58ac-467e-bcb7-da78fe8b726c",
   "metadata": {},
   "source": [
    "Ray is a framework to orchestrate HPO search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13f977-c891-4b4a-81e8-8648a7e8e9f1",
   "metadata": {},
   "source": [
    "Ray\\[Tune\\] is a mature optimization framework compatible with both PyTorch and TensorFlow, with specific integration with Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522b8c9-fd4e-40fc-82ad-73d19016611f",
   "metadata": {},
   "source": [
    "Building a deep learning estimator requires to gradually converge to a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673e069-f12e-45c5-91c1-659175c88a6c",
   "metadata": {},
   "source": [
    "Ray produces a lot of logs..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a024a37-5f1c-4241-aca8-1c0911d602c5",
   "metadata": {},
   "source": [
    "## Understanding the logic behind an HPO framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae2212-8837-4a58-83a7-c137f4935e77",
   "metadata": {},
   "source": [
    "Achieving HPO is a 4-step process:\n",
    "* Making a selection of the HParams you wish to optimize for, and setting the search space (and choosing for each parameter a sampling method.)\n",
    "* A callback to monitor and automatically report metrics progress during training\n",
    "* A trials scheduler to kill unpromising HP sets\n",
    "* A search algorithm used to explore the HP space\n",
    "* A logger to push values to a possibly remote monitor solution\n",
    "* A runner to sequentially execute experiments with the set of HP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffddb2-8406-4eec-a8ff-cf77ae10c046",
   "metadata": {},
   "source": [
    "HPO allows to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3edafc4-1c3c-42ae-94af-5efac1f873df",
   "metadata": {},
   "source": [
    "Let's first load all the necessary params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca479b7-eca0-4240-8352-cfc67db2d808",
   "metadata": {},
   "source": [
    "We will implement all of these components "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cadc9b-200f-4ab3-9a35-8bbff2f165d1",
   "metadata": {},
   "source": [
    "## Exploring components in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d074c-22ad-4cca-9101-8bd43ba1639a",
   "metadata": {},
   "source": [
    "## First fully functional example with no HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015525e-f1bb-4602-961c-ee2b92b2d04c",
   "metadata": {},
   "source": [
    "### **Search space**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93208327-75ac-46ef-8ba2-ff08a073f969",
   "metadata": {},
   "source": [
    "Each HP has its own space. Ray comes standard with a range of params types. Report \n",
    "* `tune.uniform`, `tune.quniform`, and `tune.qloguniform` to uniformly sample a float in a range of values\n",
    "* `tune.randn`, `tune.qrandn`, `tune.randint`, `tune.qrandint`, `tune.lograndint`, and `tune.qlograndint` to uniformly sample an integer in a range of values\n",
    "* `tune.choice` to sample from a discrete list of values\n",
    "* `tune.sample_from` for a custom-made sampling method\n",
    "* `tune.grid_search` to end-up browsing an entire list sequentially\n",
    "\n",
    "Create a config `dict` for data and models HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580574c0-4ec3-4875-aca5-28660df6ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"batch_size\": tune.choice([2 ** k for k in np.arange(4, 8)])\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"in_channels\": 20,\n",
    "        \"out_channels\": 4,\n",
    "        \"hidden_channels\": int(tune.choice([2 ** k for k in np.arange(4, 6)]).sample()),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"dropout\": tune.uniform(0, 1),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd3b7fb7-aaea-4f67-ba6f-b262462ac47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_feats = config[\"model\"][\"hidden_channels\"]\n",
    "hidden_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac50e1a-2ca3-4ac3-9ba3-2f774940c0ab",
   "metadata": {},
   "source": [
    "### **Runner**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a3bbf-b457-404d-b31d-718fd2e5fc95",
   "metadata": {},
   "source": [
    "The overall is a simple 3-step process\n",
    "\n",
    "1. Sample parameters to make up an HP set, following a specific search algorithm\n",
    "2. Build an execution stack with desired number of runs, then start at the top\n",
    "3. Monitor the training on relevant metrics, stop unpromising trainings early, and move the stack with freed-up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a85c3-66e7-4c91-8715-a2d45adb0cd0",
   "metadata": {},
   "source": [
    "The runner will execute runs sequentially`trainable` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2bfda7-9b48-4a5c-8842-bb238428c11f",
   "metadata": {},
   "source": [
    "trainable = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c1b03-5087-4f6a-a038-f0361b797a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(trainable, num_samples=10)\n",
    "\n",
    "# Run 1 trial, stop when trial has reached 10 iterations\n",
    "tune.run(my_trainable, stop={\"training_iteration\": 10})\n",
    "\n",
    "# automatically retry failed trials up to 3 times\n",
    "tune.run(my_trainable, stop={\"training_iteration\": 10}, max_failures=3)\n",
    "\n",
    "# Run 1 trial, search over hyperparameters, stop after 10 iterations.\n",
    "space = {\"lr\": tune.uniform(0, 1), \"momentum\": tune.uniform(0, 1)}\n",
    "tune.run(my_trainable, config=space, stop={\"training_iteration\": 10})\n",
    "\n",
    "# Resumes training if a previous machine crashed\n",
    "tune.run(my_trainable, config=space,\n",
    "         local_dir=<path/to/dir>, resume=True)\n",
    "\n",
    "# Rerun ONLY failed trials after an experiment is finished.\n",
    "tune.run(my_trainable, config=space,\n",
    "         local_dir=<path/to/dir>, resume=\"ERRORED_ONLY\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
