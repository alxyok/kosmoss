{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523e7e12-dac9-47c4-8d67-a210ff80daea",
   "metadata": {},
   "source": [
    "# 1. Scaling UP (mono-node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf5bcd-16b3-4425-8c1b-d47ef2fc3f23",
   "metadata": {},
   "source": [
    "A Note on GPU training. We naturally assume that GPU is better than CPU, but it really depends on the workflow. You need to saturate the GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebfdb2-ed51-4a06-9230-9d44af08bc7c",
   "metadata": {},
   "source": [
    "Now let's go single-node multi-GPU. The same model will be pushed to all available devices, each of which will\n",
    "1. Perform forward pass with its specific batch of data\n",
    "2. Compute the loss and perform backward pass including weights update\n",
    "4. The weights are then collected are synchronized across all devices for next pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fc516-0a24-450c-bd45-0840f9a8b9b8",
   "metadata": {},
   "source": [
    "#### **Cleanup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181424c-68e4-4a06-9361-2464b51f0525",
   "metadata": {},
   "source": [
    "You might need to clean up your ghost runs if something fails and break the training logic. You can do this one of two ways:\n",
    "* If run inside the same PID as the training from a `python train.py`:\n",
    "<code>\n",
    "import gc, torch; gc.collect(); torch.cuda.empty_cache()\n",
    "</code>\n",
    "* Otherwise, try to kill the job still running on the GPU, by get the ghost job's PID with the command `nvitop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a434084d-9827-458a-8835-3281f4f04803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 17 14:37:20 2022\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     │\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ Volatile Uncorr. ECC │\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\n",
      "│\u001b[32m   0  Tesla P100-PCIE...  Off  \u001b[0m│\u001b[32m 00000000:00:04.0 Off \u001b[0m│\u001b[32m                    0 \u001b[0m│\n",
      "│\u001b[32m MAX   41C    P0    27W / 250W \u001b[0m│\u001b[32m      2MiB / 16281MiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[32m   1  Tesla P100-PCIE...  Off  \u001b[0m│\u001b[32m 00000000:00:05.0 Off \u001b[0m│\u001b[32m                    0 \u001b[0m│\n",
      "│\u001b[32m MAX   38C    P0    27W / 250W \u001b[0m│\u001b[32m      2MiB / 16281MiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\n",
      "\u001b[1m\u001b[36m[ CPU: ▍ 1.3%                             ]\u001b[0m  \u001b[1m( Load Average:  0.27  2.21  1.80 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: ██▊ 9.3%                           ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: ▏ 0.0%                     ]\u001b[0m\n",
      "\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Processes:                                               \u001b[1m\u001b[35mjupyter\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32malx-devel-2\u001b[0m │\n",
      "│ GPU     PID      USER  GPU-MEM %SM  %CPU  %MEM  TIME  COMMAND                │\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\n",
      "│  No running processes found                                                  │\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c8c407-77c8-4996-8b61-02931a536e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: (99999999): No such process\n"
     ]
    }
   ],
   "source": [
    "# Replace in the command below the PID=99999999 by the PID number produced by nvitop\n",
    "!sudo kill -15 99999999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0b0bb-8d00-4755-9627-35400021164e",
   "metadata": {},
   "source": [
    "## 1.1. Achieving Data Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcddaec-41af-48e4-abc1-049ddd51771d",
   "metadata": {},
   "source": [
    "#### **1.1.1. Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b1f56-ceba-420d-b0c6-a15405b7ff7b",
   "metadata": {},
   "source": [
    "DP consists of parallelizing the model, and training each instance of the model with a different mini-batch of data of size `batch_size // num_parallel_instances`. Each model will converge differently on its mini-batch, so the weights are collected and usually averaged after `p` batches, then synchronized with all instances for the next round of passes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b4c97-7b50-4a5c-990e-209cc0db5635",
   "metadata": {},
   "source": [
    "#### **0. Over CPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdce8d-9047-4185-b688-5af9330b671f",
   "metadata": {},
   "source": [
    "Let's launch a reference training on CPU. Take a look at the `_trainup_cpu.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81332c0-32d3-47f8-9912-dc4db5207038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Traceback (most recent call last):\n",
      "  File \"trainup_cpu.py\", line 68, in <module>\n",
      "    args.num_processes\n",
      "  File \"trainup_cpu.py\", line 25, in main\n",
      "    out_channels=y_feats\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kosmoss/parallel/models.py\", line 104, in __init__\n",
      "    self.normalization_layer = LitMLP.Normalize(self.epsilon)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kosmoss/parallel/models.py\", line 80, in __init__\n",
      "    stats = torch.load(osp.join(DATA_PATH, f\"stats-flattened-{step}.pt\"))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/jupyter/.kosmoss/data/stats-flattened-1000.pt'\n"
     ]
    }
   ],
   "source": [
    "!python trainup_cpu.py --batch-size 512 \\\n",
    "                       --num-processes 2 > ${HOME}/.kosmoss/logs/trainup_cpu.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18532a-4a29-4ffd-9b06-c60f636cc627",
   "metadata": {},
   "source": [
    "#### **1. Launching a training on GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52ae8c9-f0ec-4103-b18d-1c86951af0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os.path as osp\n",
      "import psutil\n",
      "from pytorch_lightning import Trainer, seed_everything\n",
      "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
      "from typing import Union\n",
      "\n",
      "from kosmoss import CONFIG, LOGS_PATH, METADATA\n",
      "from kosmoss.parallel.data import FlattenedDataModule\n",
      "from kosmoss.parallel.models import LitMLP\n",
      "\n",
      "def main(batch_size: int,\n",
      "         lr: float,\n",
      "         strategy: Union['ddp', 'horovod'],\n",
      "         gpus: int,\n",
      "         num_nodes: int) -> None:\n",
      "\n",
      "    seed_everything(42, workers=True)\n",
      "    \n",
      "    step = CONFIG['timestep']\n",
      "    params = METADATA[str(step)]['flattened']\n",
      "\n",
      "    x_feats = params['x_shape'][-1]\n",
      "    y_feats = params['y_shape'][-1]\n",
      "\n",
      "    mlp = LitMLP(\n",
      "        in_channels=x_feats,\n",
      "        hidden_channels=100,\n",
      "        out_channels=y_feats,\n",
      "        \n",
      "        # Adjust the learning rate accordingly to account for the increase in total batch size\n",
      "        # Or use a Lightning LR Finder functionality, or any other framework's finder\n",
      "        lr=lr,\n",
      "    )\n",
      "\n",
      "    cores = psutil.cpu_count(logical=False)\n",
      "    datamodule = FlattenedDataModule(\n",
      "        \n",
      "        # Adjust the total batch size with regards to the number of nodes and GPUs per node\n",
      "        batch_size=batch_size // (num_nodes * gpus),\n",
      "        num_workers=cores\n",
      "    )\n",
      "\n",
      "    logger = TensorBoardLogger(\n",
      "        save_dir=LOGS_PATH,\n",
      "        name='flattened_mlp_logs',\n",
      "        log_graph=True\n",
      "    )\n",
      "\n",
      "    gpu_trainer = Trainer(\n",
      "        strategy=strategy,\n",
      "        gpus=gpus,\n",
      "        \n",
      "        # If you're using a batch normalization layer\n",
      "        # The following flag can allow sync accros total batch instead of local minibatch\n",
      "        # sync_batchnorm=True,\n",
      "        \n",
      "        max_epochs=1,\n",
      "        logger=logger,\n",
      "        deterministic=True,\n",
      "        num_sanity_val_steps=0,\n",
      "        num_nodes=num_nodes\n",
      "        \n",
      "        # Uncomment if you want to use Nvidia's own implementation of AMP called APEX\n",
      "        # amp_backend='apex',\n",
      "        \n",
      "        # Useful if you want to profile your training for debug purposes\n",
      "        # profiler=\"simple\"\n",
      "    )\n",
      "    gpu_trainer.fit(model=mlp, datamodule=datamodule)\n",
      "    gpu_trainer.test(model=mlp, datamodule=datamodule)\n",
      "\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    \n",
      "    import argparse\n",
      "    \n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument('--batch-size', \n",
      "                        type=int,\n",
      "                        help='Total batch size', \n",
      "                        default=16)\n",
      "    parser.add_argument('--lr', \n",
      "                        type=float,\n",
      "                        help='Learning Rate', \n",
      "                        default=1e-4)\n",
      "    parser.add_argument('--strategy', \n",
      "                        type=str,\n",
      "                        help='Data Distributed Strategy', \n",
      "                        default='ddp')\n",
      "    parser.add_argument('--gpus', \n",
      "                        type=int,\n",
      "                        help='Number of GPUs to accelerate over', \n",
      "                        default=1)\n",
      "    parser.add_argument('--num-nodes', \n",
      "                        type=int,\n",
      "                        help='Number of nodes to accelerate over', \n",
      "                        default=1)\n",
      "    args = parser.parse_args()\n",
      "    \n",
      "    main(\n",
      "        args.batch_size, \n",
      "        args.lr,\n",
      "        args.strategy, \n",
      "        args.gpus,\n",
      "        args.num_nodes\n",
      "    )"
     ]
    }
   ],
   "source": [
    "!cat trainup_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0164d-921b-450a-886e-24e0031dd942",
   "metadata": {},
   "source": [
    "Let's launch the training with 2 nodes and 1 GPU/node. Since we're on a single node, each node designates an independent process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9f1fd8-16f2-4e20-b97d-9b5b6d078338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 42\n",
      "initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "bash: line 5: 28849 Killed                  python trainup_gpu.py --batch-size 512 --lr=1e-4 --strategy 'ddp' --gpus 1 --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_ddp.stdout\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b\"python trainup_gpu.py --batch-size 512 \\\\\\n                      --lr=1e-4 \\\\\\n                      --strategy 'ddp' \\\\\\n                      --gpus 1 \\\\\\n                      --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_ddp.stdout\\n\"' returned non-zero exit status 137.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16538/1576396842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"python trainup_gpu.py --batch-size 512 \\\\\\n                      --lr=1e-4 \\\\\\n                      --strategy 'ddp' \\\\\\n                      --gpus 1 \\\\\\n                      --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_ddp.stdout\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b\"python trainup_gpu.py --batch-size 512 \\\\\\n                      --lr=1e-4 \\\\\\n                      --strategy 'ddp' \\\\\\n                      --gpus 1 \\\\\\n                      --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_ddp.stdout\\n\"' returned non-zero exit status 137."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python trainup_gpu.py --batch-size 512 \\\n",
    "                      --lr=1e-4 \\\n",
    "                      --strategy 'ddp' \\\n",
    "                      --gpus 1 \\\n",
    "                      --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_ddp.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278d105-9dd9-4a76-8abb-abc77f7e346c",
   "metadata": {},
   "source": [
    "#### **1.1.2. Horovod**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1aa2c-5ea9-4726-8f49-e4391ebcc295",
   "metadata": {},
   "source": [
    "With a simple change in the Trainer options, you can rely on horovod backend to perform the computations. Prallelism is achieved by SPMD with MPI: one process per GPU potentially distributed accross multiple nodes, and collective computing is made by process of rank 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc42e3d-483e-408e-a67b-bca8af394799",
   "metadata": {},
   "source": [
    "No need to adjust the learning rate `lr` this time, horovod takes care of that underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987074b-ddc3-454b-834c-4bd86de75025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python trainup_gpu.py --batch-size 512 \\\n",
    "                      --strategy 'horovod' \\\n",
    "                      --gpus 1 \\\n",
    "                      --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_horovod.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67b3c6-ebdb-4780-be9d-ab6a8768eabe",
   "metadata": {},
   "source": [
    "## **1.2. A Note on Model Parallelism**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280a2db-6f67-41b7-85b6-d4a44af262de",
   "metadata": {},
   "source": [
    "You should really go for model parallelism starting at 500M parameters. No material on that, just know that it exists and it is complex subject that would require an entire session. Lightning comes standard with a series of distrubtion strategies, each with a specific implementation related to the network that first introduced it.\n",
    "\n",
    "Refer to the Doc for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1df06b-1cd5-4f84-8bbf-03eaa6fc4937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
