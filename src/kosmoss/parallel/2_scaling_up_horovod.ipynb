{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523e7e12-dac9-47c4-8d67-a210ff80daea",
   "metadata": {},
   "source": [
    "# 1. Scaling UP (mono-node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf5bcd-16b3-4425-8c1b-d47ef2fc3f23",
   "metadata": {},
   "source": [
    "A Note on GPU training. We naturally assume that GPU is better than CPU, but it really depends on the workflow. You need to saturate the GPU memory, and compute surface.\n",
    "\n",
    "This session is focused on providing the candidates with minimum information to scale their current workflow with HW acceleration **AT THE APPLICATION LEVEL**. Low-level, high-value optimization is also a viable angle to address distributed training and inference, but this session does not cover it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b21f73-cca9-4061-aaee-6014690fb77f",
   "metadata": {},
   "source": [
    "## What's with GPUs anyway?\n",
    "\n",
    "DL is basically linear algebra, with a few non-linear Maths. It turns out, GPUs are a great tool to process that kind of computations. A few pieces of information\n",
    "\n",
    "In 2022, Nvidia is the leader in HW dedicated to DL. The company was the first to develop and push a [suite of libraries based on CUDA](https://developer.nvidia.com/gpu-accelerated-libraries) called CUDA-X for HW acceleration of ML/DL workloads, among which:\n",
    "* `cuBLAS`, `cuFFT`, `CUDA MathLib`, `cuRAND`, `cuSOLVER`, `cuSPARSE`, `cuTENSOR` for GPU-accelerated basic linear algebra (2D + nD), Fast Fourier Transform, and standard Math primitives, computations on sparse matrices\n",
    "* `cuDNN` for GPU-accelerated primitives for Deep NN\n",
    "* `TensorRT` for high-performance DL inference optimizer and runtime for production deployment\n",
    "* `DALI`, a portable open-source format for decoding and agumenting images and videos\n",
    "* Additionally, Nvidia GPUs rely on the NCCL library for fast, multi-GPU, multi-node communications, also a great tool for distributed DL.\n",
    "\n",
    "AMD also has a less-mature ML support with the [ROCm framework](https://www.amd.com/en/graphics/servers-solutions-rocm-ml).\n",
    "\n",
    "A few startups have started to tackle the HW problem on very different angles, notably:\n",
    "* [Graphcore](https://www.graphcore.ai/products/ipu) with its IPU die—250 TFlop and high in-processor-memory—, and SW stack (Poplar SDK) to convert existing TF and PT models into IPU-executable code\n",
    "* [Cerebras](https://cerebras.net/chip/) with its massive 850,000 cores chip—the Wafer-Scale Engine—and high-bandwidth memory and memory-per-core\n",
    "\n",
    "Google has also invested in Tensor-optimized HW with its [TPU devices](https://cloud.google.com/tpu) now only available in its [cloud platform GCP](https://cloud.google.com/) since version 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fc516-0a24-450c-bd45-0840f9a8b9b8",
   "metadata": {},
   "source": [
    "## A note on cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181424c-68e4-4a06-9361-2464b51f0525",
   "metadata": {},
   "source": [
    "You might need to clean up your ghost runs if something fails and break the training logic. You can do this one of two ways:\n",
    "* If run inside the same PID as the training from a `python train.py`:\n",
    "<code>\n",
    "import gc, torch; gc.collect(); torch.cuda.empty_cache()\n",
    "</code>\n",
    "* Otherwise, try to kill the job still running on the GPU, by get the ghost job's PID with the command `nvitop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a434084d-9827-458a-8835-3281f4f04803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 17 14:37:20 2022\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     │\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ Volatile Uncorr. ECC │\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\n",
      "│\u001b[32m   0  Tesla P100-PCIE...  Off  \u001b[0m│\u001b[32m 00000000:00:04.0 Off \u001b[0m│\u001b[32m                    0 \u001b[0m│\n",
      "│\u001b[32m MAX   41C    P0    27W / 250W \u001b[0m│\u001b[32m      2MiB / 16281MiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "├───────────────────────────────┼──────────────────────┼──────────────────────┤\n",
      "│\u001b[32m   1  Tesla P100-PCIE...  Off  \u001b[0m│\u001b[32m 00000000:00:05.0 Off \u001b[0m│\u001b[32m                    0 \u001b[0m│\n",
      "│\u001b[32m MAX   38C    P0    27W / 250W \u001b[0m│\u001b[32m      2MiB / 16281MiB \u001b[0m│\u001b[32m      0%      Default \u001b[0m│\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\n",
      "\u001b[1m\u001b[36m[ CPU: ▍ 1.3%                             ]\u001b[0m  \u001b[1m( Load Average:  0.27  2.21  1.80 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: ██▊ 9.3%                           ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: ▏ 0.0%                     ]\u001b[0m\n",
      "\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Processes:                                               \u001b[1m\u001b[35mjupyter\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32malx-devel-2\u001b[0m │\n",
      "│ GPU     PID      USER  GPU-MEM %SM  %CPU  %MEM  TIME  COMMAND                │\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\n",
      "│  No running processes found                                                  │\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c8c407-77c8-4996-8b61-02931a536e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: (99999999): No such process\n"
     ]
    }
   ],
   "source": [
    "# Replace in the command below the PID=99999999 by the PID number produced by nvitop\n",
    "!sudo kill -15 99999999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0b0bb-8d00-4755-9627-35400021164e",
   "metadata": {},
   "source": [
    "## 1.1. Achieving Data Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebfdb2-ed51-4a06-9230-9d44af08bc7c",
   "metadata": {},
   "source": [
    "Now let's go single-node multi-GPU. The same model will be pushed to all available devices, each of which will\n",
    "1. Perform forward pass with its specific batch of data\n",
    "2. Compute the loss and perform backward pass including weights update\n",
    "4. The weights are then collected are synchronized across all devices for next pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcddaec-41af-48e4-abc1-049ddd51771d",
   "metadata": {},
   "source": [
    "#### **1.1.1. Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b1f56-ceba-420d-b0c6-a15405b7ff7b",
   "metadata": {},
   "source": [
    "DP consists of parallelizing the model, and training each instance of the model with a different mini-batch of data of size `batch_size // num_parallel_instances`. Each model will converge differently on its mini-batch, so the weights are collected and usually averaged after `p` batches, then synchronized with all instances for the next round of passes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b4c97-7b50-4a5c-990e-209cc0db5635",
   "metadata": {},
   "source": [
    "#### **0. Over CPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdce8d-9047-4185-b688-5af9330b671f",
   "metadata": {},
   "source": [
    "Let's launch a reference training on CPU. Take a look at the `trainup_cpu.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81332c0-32d3-47f8-9912-dc4db5207038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Traceback (most recent call last):\n",
      "  File \"trainup_cpu.py\", line 68, in <module>\n",
      "    args.num_processes\n",
      "  File \"trainup_cpu.py\", line 25, in main\n",
      "    out_channels=y_feats\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kosmoss/parallel/models.py\", line 104, in __init__\n",
      "    self.normalization_layer = LitMLP.Normalize(self.epsilon)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/kosmoss/parallel/models.py\", line 80, in __init__\n",
      "    stats = torch.load(osp.join(DATA_PATH, f\"stats-flattened-{step}.pt\"))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/jupyter/.kosmoss/data/stats-flattened-1000.pt'\n"
     ]
    }
   ],
   "source": [
    "!python trainup_cpu.py --batch-size 512 \\\n",
    "                       --num-processes 2 > ${HOME}/.kosmoss/logs/trainup_cpu.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18532a-4a29-4ffd-9b06-c60f636cc627",
   "metadata": {},
   "source": [
    "#### **1. Launching a training on GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52ae8c9-f0ec-4103-b18d-1c86951af0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os.path as osp\n",
      "import psutil\n",
      "from pytorch_lightning import Trainer, seed_everything\n",
      "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
      "from typing import Union\n",
      "\n",
      "from kosmoss import CONFIG, LOGS_PATH, METADATA\n",
      "from kosmoss.parallel.data import FlattenedDataModule\n",
      "from kosmoss.parallel.models import LitMLP\n",
      "\n",
      "def main(batch_size: int,\n",
      "         lr: float,\n",
      "         strategy: Union['ddp', 'horovod'],\n",
      "         gpus: int,\n",
      "         num_nodes: int) -> None:\n",
      "\n",
      "    seed_everything(42, workers=True)\n",
      "    \n",
      "    step = CONFIG['timestep']\n",
      "    params = METADATA[str(step)]['flattened']\n",
      "\n",
      "    x_feats = params['x_shape'][-1]\n",
      "    y_feats = params['y_shape'][-1]\n",
      "\n",
      "    mlp = LitMLP(\n",
      "        in_channels=x_feats,\n",
      "        hidden_channels=100,\n",
      "        out_channels=y_feats,\n",
      "        \n",
      "        # Adjust the learning rate accordingly to account for the increase in total batch size\n",
      "        # Or use a Lightning LR Finder functionality, or any other framework's finder\n",
      "        lr=lr,\n",
      "    )\n",
      "\n",
      "    cores = psutil.cpu_count(logical=False)\n",
      "    datamodule = FlattenedDataModule(\n",
      "        \n",
      "        # Adjust the total batch size with regards to the number of nodes and GPUs per node\n",
      "        batch_size=batch_size // (num_nodes * gpus),\n",
      "        num_workers=cores\n",
      "    )\n",
      "\n",
      "    logger = TensorBoardLogger(\n",
      "        save_dir=LOGS_PATH,\n",
      "        name='flattened_mlp_logs',\n",
      "        log_graph=True\n",
      "    )\n",
      "\n",
      "    gpu_trainer = Trainer(\n",
      "        strategy=strategy,\n",
      "        gpus=gpus,\n",
      "        \n",
      "        # If you're using a batch normalization layer\n",
      "        # The following flag can allow sync accros total batch instead of local minibatch\n",
      "        # sync_batchnorm=True,\n",
      "        \n",
      "        max_epochs=1,\n",
      "        logger=logger,\n",
      "        deterministic=True,\n",
      "        num_sanity_val_steps=0,\n",
      "        num_nodes=num_nodes\n",
      "        \n",
      "        # Uncomment if you want to use Nvidia's own implementation of AMP called APEX\n",
      "        # amp_backend='apex',\n",
      "        \n",
      "        # Useful if you want to profile your training for debug purposes\n",
      "        # profiler=\"simple\"\n",
      "    )\n",
      "    gpu_trainer.fit(model=mlp, datamodule=datamodule)\n",
      "    gpu_trainer.test(model=mlp, datamodule=datamodule)\n",
      "\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    \n",
      "    import argparse\n",
      "    \n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument('--batch-size', \n",
      "                        type=int,\n",
      "                        help='Total batch size', \n",
      "                        default=16)\n",
      "    parser.add_argument('--lr', \n",
      "                        type=float,\n",
      "                        help='Learning Rate', \n",
      "                        default=1e-4)\n",
      "    parser.add_argument('--strategy', \n",
      "                        type=str,\n",
      "                        help='Data Distributed Strategy', \n",
      "                        default='ddp')\n",
      "    parser.add_argument('--gpus', \n",
      "                        type=int,\n",
      "                        help='Number of GPUs to accelerate over', \n",
      "                        default=1)\n",
      "    parser.add_argument('--num-nodes', \n",
      "                        type=int,\n",
      "                        help='Number of nodes to accelerate over', \n",
      "                        default=1)\n",
      "    args = parser.parse_args()\n",
      "    \n",
      "    main(\n",
      "        args.batch_size, \n",
      "        args.lr,\n",
      "        args.strategy, \n",
      "        args.gpus,\n",
      "        args.num_nodes\n",
      "    )"
     ]
    }
   ],
   "source": [
    "!cat trainup_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0164d-921b-450a-886e-24e0031dd942",
   "metadata": {},
   "source": [
    "Let's launch the training with 2 nodes and 1 GPU/node. Since we're on a single node, each node designates an independent process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f1fd8-16f2-4e20-b97d-9b5b6d078338",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python trainup_gpu.py --batch-size 512 \\\n",
    "                      --lr=1e-4 \\\n",
    "                      --strategy 'ddp' \\\n",
    "                      --gpus 1 \\\n",
    "                      --num-nodes 2 > ${HOME}/.kosmoss/logs/trainup_gpu_ddp.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67b3c6-ebdb-4780-be9d-ab6a8768eabe",
   "metadata": {},
   "source": [
    "## **1.2. A Note on Model Parallelism**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280a2db-6f67-41b7-85b6-d4a44af262de",
   "metadata": {},
   "source": [
    "You should really go for model parallelism starting at 500M parameters. \n",
    "\n",
    "No material on that since the subject is complex and would require an entire session, just know that it exists. Lightning comes standard with a series of distrubtion strategies, each with a specific implementation related to the network that first introduced it. [More info](https://pytorch-lightning.readthedocs.io/en/stable/advanced/advanced_gpu.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1df06b-1cd5-4f84-8bbf-03eaa6fc4937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
